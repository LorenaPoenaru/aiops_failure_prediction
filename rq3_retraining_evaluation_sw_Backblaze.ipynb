{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fcc4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985e07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73148363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_seeds = list(np.arange(0, 30))\n",
    "random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(random_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_intervals(dataset):\n",
    "    '''\n",
    "    Generate interval terminals, so that samples in each interval have:\n",
    "        interval_i = (timestamp >= terminal_i) and (timestamp < terminal_{i+1})\n",
    "\n",
    "    Args:\n",
    "        dataset (chr): Assuming only Backblaze (b) and Google (g) datasets exists\n",
    "    '''\n",
    "    if dataset == 'g':\n",
    "        # time unit in Google: millisecond, tracing time: 29 days\n",
    "        start_time = 604046279\n",
    "        unit_period = 24 * 60 * 60 * 1000 * 1000  # unit period: one day\n",
    "        end_time = start_time + 28*unit_period\n",
    "    elif dataset == 'b':\n",
    "        # time unit in Backblaze: month, tracing time: one year (12 months)\n",
    "        start_time = 1\n",
    "        unit_period = 1  # unit period: one month\n",
    "        end_time = start_time + 12*unit_period\n",
    "    \n",
    "    # add one unit for the open-end of range function\n",
    "    terminals = [i for i in range(start_time, end_time+unit_period, unit_period)]\n",
    "\n",
    "    return terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d205719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_natural_chunks(features, labels, terminals):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(terminals) - 1):\n",
    "        idx = np.logical_and(features[:, 0] >= terminals[i], features[:, 0] < terminals[i + 1])\n",
    "        feature_list.append(features[idx][:, 1:])\n",
    "        label_list.append(labels[idx])\n",
    "    return feature_list, label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d06b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(training_features, training_labels, ratio=10):\n",
    "    #return training_features, training_labels\n",
    "\n",
    "    idx_true = np.where(training_labels == True)[0]\n",
    "    idx_false = np.where(training_labels == False)[0]\n",
    "    #print('Before dowmsampling:', len(idx_true), len(idx_false))\n",
    "    idx_false_resampled = resample(idx_false, n_samples=len(idx_true)*ratio, replace=False, random_state = random_seed)\n",
    "    idx_resampled = np.concatenate([idx_false_resampled, idx_true])\n",
    "    idx_resampled.sort()\n",
    "    resampled_features = training_features[idx_resampled]\n",
    "    resampled_labels = training_labels[idx_resampled]\n",
    "    #print('After dowmsampling:', len(idx_true), len(idx_false_resampled))\n",
    "    return resampled_features, resampled_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a584a6f0",
   "metadata": {},
   "source": [
    "Feature Importance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5795ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features_extraction(model, features_input):\n",
    "    \n",
    "    # extract features and their importances\n",
    "    \n",
    "    feature_importance_ranking = model.feature_importances_\n",
    "    zipped_features = list(zip(feature_importance_ranking, features_input))\n",
    "    sorted_features_zip = sorted(zipped_features, key = lambda x: x[0], reverse = True)\n",
    "    \n",
    "    # extract mean of importances\n",
    "    \n",
    "    importances = [i[0] for i in sorted_features_zip]\n",
    "    mean_importances = np.mean(importances)\n",
    "    \n",
    "    # extract most important features and return\n",
    "    \n",
    "    most_important_features = [i[1] for i in sorted_features_zip if i[0]>= mean_importances]\n",
    "    \n",
    "    return most_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_non_important_features(features_array, features_names, important_features_names):\n",
    "    # transform array into dataframe and attach features\n",
    "    df_features = pd.DataFrame(np.array(features_array), columns = features_names)\n",
    "    \n",
    "    # filter out columns with non-relevant features\n",
    "    df_important_features = df_features[df_features.columns[~df_features.columns.isin(important_features)==0]]\n",
    "    \n",
    "    # transform dataframe with only into features back into array\n",
    "    important_features_array = df_important_features.to_numpy()\n",
    "    \n",
    "    return important_features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_preprocessing(DATASET_PATH, dataset):\n",
    "    \n",
    "    if(dataset=='b'):\n",
    "        \n",
    "        print('Data Reading and Preprocessing')\n",
    "        \n",
    "        # set data paths and columns names\n",
    "        features_disk_failure = ['smart_1_raw', 'smart_4_raw', 'smart_5_raw', 'smart_7_raw', 'smart_9_raw', 'smart_12_raw', 'smart_187_raw', 'smart_193_raw', 'smart_194_raw', 'smart_197_raw', 'smart_199_raw', \n",
    "                         'smart_4_raw_diff', 'smart_5_raw_diff', 'smart_9_raw_diff', 'smart_12_raw_diff', 'smart_187_raw_diff', 'smart_193_raw_diff', 'smart_197_raw_diff', 'smart_199_raw_diff']\n",
    "        columns = ['serial_number', 'date'] + features_disk_failure + ['label']\n",
    "        \n",
    "        # read dataset\n",
    "        df = pd.read_csv(DATASET_PATH_DISK, header=None, dtype = 'str').iloc[1:,1:]\n",
    "        df.columns = columns\n",
    "        \n",
    "        # ignore serial number\n",
    "        df = df[df.columns[1:]]\n",
    "        \n",
    "        for feature in features_disk_failure:\n",
    "            df[feature] = df[feature].astype(float)\n",
    "\n",
    "\n",
    "        d = {'True': True, 'False': False}\n",
    "        df['label'] = df['label'].map(d)\n",
    "\n",
    "        df['label'].unique()\n",
    "\n",
    "        # transform date to date time\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "        # divide on weeks\n",
    "        df['date'] = pd.Series(pd.DatetimeIndex(df['date']).day_of_year)\n",
    "        \n",
    "        print('Features and Labels Computing')\n",
    "        \n",
    "        # features and labels extraction and computation\n",
    "        features = df[df.columns[:-1]].to_numpy()\n",
    "        labels = df[df.columns[-1]].to_numpy()\n",
    "        feature_list, label_list = obtain_natural_chunks(features, labels, obtain_intervals('b'))\n",
    "        \n",
    "    elif(dataset=='g'):\n",
    "        \n",
    "        print('Data Reading and Preprocessing')\n",
    "        \n",
    "        # set data paths and columns names\n",
    "        features_job_failure = ['User ID', 'Job Name', 'Scheduling Class',\n",
    "                   'Num Tasks', 'Priority', 'Diff Machine', 'CPU Requested', 'Mem Requested', 'Disk Requested',\n",
    "                   'Avg CPU', 'Avg Mem', 'Avg Disk', 'Std CPU', 'Std Mem', 'Std Disk']\n",
    "        columns_initial = ['Job ID', 'Status', 'Start Time', 'End Time'] + features_job_failure\n",
    "        \n",
    "        # read dataset\n",
    "        df = pd.read_csv(DATASET_PATH, header=None)\n",
    "        df.columns = columns_initial\n",
    "        df = df.tail(-1)\n",
    "        # ignore Job ID\n",
    "        df = df.drop(['Job ID'], axis = 1)\n",
    "        columns = features_job_failure\n",
    "\n",
    "        include_end_time = False\n",
    "        \n",
    "        print('Features and Labels Preprocessing')\n",
    "        \n",
    "        # features and labels preprocessing\n",
    "        features = df[(['Start Time']+ features_job_failure)].to_numpy()\n",
    "        labels = (df['Status']==3).to_numpy()\n",
    "\n",
    "        # FEATURES PREPROCESSING\n",
    "        offset = (1 if include_end_time else 0)\n",
    "\n",
    "        # ENCODE USER ID\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        features[:, 1+offset] = le.fit_transform(features[:, 1+offset])\n",
    "\n",
    "        # ENCODE JOB NAME\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        features[:, 2+offset] = le.fit_transform(features[:, 2+offset])\n",
    "\n",
    "        features = features.astype(float)\n",
    "        \n",
    "        print('Features and Labels Computing')\n",
    "        \n",
    "        # features and labels extraction and computation\n",
    "        feature_list, label_list = obtain_natural_chunks(features, labels, obtain_intervals('g'))\n",
    "        \n",
    "    else:\n",
    "        print('Incorrect Dataset')\n",
    "    \n",
    "    return feature_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cb9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_drift_detection(reference_data, testing_data):\n",
    "    \n",
    "    # extract distributions from reference and testing data\n",
    "    \n",
    "    distribution_extraction_time_start = time.time()\n",
    "    distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    distribution_extraction_time_end = time.time() - distribution_extraction_time_start\n",
    "    # apply KS statistical test\n",
    "    \n",
    "    ks_test_time_start = time.time()\n",
    "    stat_test = stats.kstest\n",
    "    v, p = stat_test(distribution_reference, distribution_test)\n",
    "    ks_test_time_end = time.time() - ks_test_time_start\n",
    "    # check if drift\n",
    "    \n",
    "    if(p<0.05):\n",
    "        drift_alert = 1\n",
    "    else:\n",
    "        drift_alert = 0\n",
    "\n",
    "    return drift_alert, distribution_extraction_time_end, ks_test_time_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476062c",
   "metadata": {},
   "source": [
    "Feature Importance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe24da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features_extraction(model, features_input):\n",
    "    \n",
    "    # extract features and their importances\n",
    "    \n",
    "    feature_importance_ranking = model.feature_importances_\n",
    "    zipped_features = list(zip(feature_importance_ranking, features_input))\n",
    "    sorted_features_zip = sorted(zipped_features, key = lambda x: x[0], reverse = True)\n",
    "    \n",
    "    # extract mean of importances\n",
    "    \n",
    "    importances = [i[0] for i in sorted_features_zip]\n",
    "    mean_importances = np.mean(importances)\n",
    "    \n",
    "    # extract most important features and return\n",
    "    \n",
    "    most_important_features = [i[1] for i in sorted_features_zip if i[0]>= mean_importances]\n",
    "    \n",
    "    return most_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbeb0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_non_important_features(features_array, features_names, important_features_names):\n",
    "    # transform array into dataframe and attach features\n",
    "    df_features = pd.DataFrame(np.array(features_array), columns = features_names)\n",
    "    \n",
    "    # filter out columns with non-relevant features\n",
    "    df_important_features = df_features[df_features.columns[~df_features.columns.isin(important_features)==0]]\n",
    "    \n",
    "    # transform dataframe with only into features back into array\n",
    "    important_features_array = df_important_features.to_numpy()\n",
    "    \n",
    "    return important_features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7a667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb3283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10465761",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORKERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04462306",
   "metadata": {},
   "source": [
    "# Extracting Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed70b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH_DISK = '../../../Documents/phd_related/AIOps_disk_failure_prediction/raw_data_2015_2017/disk_2015_complete.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fe02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_disk_failure = ['smart_1_raw', 'smart_4_raw', 'smart_5_raw', 'smart_7_raw', 'smart_9_raw', 'smart_12_raw', 'smart_187_raw', 'smart_193_raw', 'smart_194_raw', 'smart_197_raw', 'smart_199_raw', \n",
    "                         'smart_4_raw_diff', 'smart_5_raw_diff', 'smart_9_raw_diff', 'smart_12_raw_diff', 'smart_187_raw_diff', 'smart_193_raw_diff', 'smart_197_raw_diff', 'smart_199_raw_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6f1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9451e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7a415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list, label_list = features_labels_preprocessing(DATASET_PATH_DISK, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc593c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e274b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original implementation\n",
    "months = ['M1_2', 'M2_3', 'M3_4', 'M4_5', 'M5_6', 'M6_7', 'M7_8', 'M8_9', 'M9_10', 'M10_11', 'M11_12']\n",
    "\n",
    "# divide on weeks\n",
    "'''\n",
    "weeks = []\n",
    "for i in range(0, len(feature_list)-1):\n",
    "    string_week = 'W' + str(i+1) + '_' + str(i+2)\n",
    "    weeks.append(string_week)\n",
    "len(weeks)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = len(feature_list)\n",
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332a6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b23eb9f4",
   "metadata": {},
   "source": [
    "## True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_testing_labels = np.hstack(label_list[num_chunks//2:])\n",
    "true_testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01d405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb76349",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER_SEARCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_rf = {\n",
    "            'n_estimators': stats.randint(1e1, 1e2),\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'max_depth': [int(x) for x in np.linspace(10, 110, num=6)] + [None],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'min_samples_split': [2, 4, 8],\n",
    "            'class_weight':['balanced', None],\n",
    "            'bootstrap': [True, False]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cb68c",
   "metadata": {},
   "source": [
    "# Static Model (No Retraining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4461e4",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ebf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029a309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for random_seed in random_seeds:\n",
    "    print('Random Seed', random_seed)\n",
    "    begin_total_static = time.time()\n",
    "    partial_roc_auc = []\n",
    "    total_test_static = 0\n",
    "\n",
    "    # extracting training features and labels\n",
    "    training_features = np.vstack(feature_list[0: num_chunks//2])\n",
    "    training_labels = np.hstack(label_list[0: num_chunks//2])\n",
    "\n",
    "    # scaling training data\n",
    "    scaler = StandardScaler()\n",
    "    training_features = scaler.fit_transform(training_features)\n",
    "\n",
    "    # downsampling training data\n",
    "    training_features_downsampling, training_labels_downsampling = downsampling(training_features, training_labels)\n",
    "\n",
    "    # training model\n",
    "    begin_train_time_static = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    begin_hyperparam_tunning_static = time.time()\n",
    "    model = RandomForestClassifier(random_state = random_seed)\n",
    "    random_search = RandomizedSearchCV(model,\n",
    "                                               param_distributions = param_dist_rf,\n",
    "                                               n_iter=N_ITER_SEARCH,\n",
    "                                               scoring='roc_auc',\n",
    "                                               cv=4, n_jobs=1)\n",
    "    print('Finding Hyperparameters')\n",
    "    random_search.fit(training_features_downsampling, training_labels_downsampling)\n",
    "\n",
    "    static_model = random_search.best_estimator_\n",
    "    \n",
    "    end_hyperparam_tunning_static = time.time() - begin_hyperparam_tunning_static\n",
    "    \n",
    "    print('Training')\n",
    "    static_model.fit(training_features_downsampling, training_labels_downsampling)\n",
    "    end_train_time_static = time.time() - begin_train_time_static\n",
    "    #print('Training time: ', end_train_time_static)\n",
    "\n",
    "    total_time_training = 0\n",
    "    predictions_test_static_model = []\n",
    "\n",
    "    # true testing labels\n",
    "    true_testing_labels = np.hstack(label_list[num_chunks//2:])\n",
    "\n",
    "\n",
    "    # lengths of tests\n",
    "    len_test = 0\n",
    "\n",
    "    print('Testing model on periods')\n",
    "    begin_test_time_static = time.time()\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "\n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        #len_test = len_test + len(testing_features)\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        # scaling testing features\n",
    "        testing_features = scaler.transform(testing_features)\n",
    "\n",
    "        # evaluate model on testing data\n",
    "        begin_test_time_static = time.time()\n",
    "        predictions_test_updated = static_model.predict(testing_features)\n",
    "        end_test_time_static = time.time() - begin_test_time_static\n",
    "        total_test_static = total_test_static + end_test_time_static\n",
    "\n",
    "        partial_roc_auc.append(roc_auc_score(testing_labels, predictions_test_updated))\n",
    "\n",
    "        predictions_test_static_model = np.concatenate([predictions_test_static_model, predictions_test_updated])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    end_total_static = time.time() - begin_total_static\n",
    "    \n",
    "    df_results_static_rf = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts', 'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Label_Costs'])\n",
    "    df_results_static_rf.loc[0] = [random_seed, 'static', '0/' + str(int(num_chunks//2)), partial_roc_auc, np.mean(partial_roc_auc), roc_auc_score(true_testing_labels, predictions_test_static_model), predictions_test_static_model, true_testing_labels, end_train_time_static, end_hyperparam_tunning_static, total_test_static, np.zeros(25, dtype=int), 0.0]\n",
    "\n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_static_rf])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/rq3_static_model_backblaze_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c982abe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f64b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6378a4e9",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd33e31",
   "metadata": {},
   "source": [
    "# Periodic Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a3cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for random_seed in random_seeds:\n",
    "\n",
    "    print('Random Seed', random_seed)\n",
    "    \n",
    "    total_time_training = 0\n",
    "    predictions_test_sw = []\n",
    "    lengths_training_sw = []\n",
    "    partial_roc_auc_sw = []\n",
    "    \n",
    "    \n",
    "\n",
    "    begin_total_sw = time.time()\n",
    "\n",
    "    total_train_sw = 0 \n",
    "    total_hyperparam_sw = 0\n",
    "    total_test_sw = 0\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "\n",
    "        # obtain training features and labels\n",
    "        training_features_init = np.vstack(feature_list[0: i])\n",
    "        training_labels_init = np.hstack(label_list[0//2: i])\n",
    "        drift_alert = 0\n",
    "\n",
    "        # check if it is the first batch\n",
    "        if(i==num_chunks//2):\n",
    "            training_features = training_features_init\n",
    "            training_labels = training_labels_init\n",
    "\n",
    "\n",
    "        # scaler and downsampling for training data\n",
    "        update_scaler = StandardScaler()\n",
    "        training_features = update_scaler.fit_transform(training_features)\n",
    "        training_features_downsampling, training_labels_downsampling = downsampling(training_features, training_labels)\n",
    "\n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        # scaling testing features\n",
    "        testing_features = update_scaler.transform(testing_features)\n",
    "\n",
    "        \n",
    "        \n",
    "        # training model\n",
    "        begin_train_sw = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        begin_hyperparam_tunning_update = time.time()\n",
    "        model = RandomForestClassifier(random_state = random_seed)\n",
    "        random_search = RandomizedSearchCV(model,\n",
    "                                                   param_distributions = param_dist_rf,\n",
    "                                                   n_iter=N_ITER_SEARCH,\n",
    "                                                   scoring='roc_auc',\n",
    "                                                   cv=4, n_jobs=1)\n",
    "        print('Finding Hyperparameters')\n",
    "        random_search.fit(training_features_downsampling, training_labels_downsampling)\n",
    "\n",
    "        update_model = random_search.best_estimator_\n",
    "        print(update_model)\n",
    "\n",
    "        end_hyperparam_tunning_update = time.time() - begin_hyperparam_tunning_update\n",
    "\n",
    "        print('Training')\n",
    "        update_model.fit(training_features_downsampling, training_labels_downsampling)\n",
    "        end_train_sw = time.time() - begin_train_sw\n",
    "        \n",
    "        \n",
    "        total_hyperparam_sw = total_hyperparam_sw + end_hyperparam_tunning_update\n",
    "        total_train_sw = total_train_sw + end_train_sw\n",
    "        \n",
    "        \n",
    "        \n",
    "        begin_test_sw = time.time()\n",
    "        \n",
    "        predictions_test_updated = update_model.predict(testing_features)\n",
    "        end_test_sw = time.time() - begin_test_sw\n",
    "        total_test_sw = total_test_sw + end_test_sw\n",
    "\n",
    "\n",
    "        partial_roc_auc_sw.append(roc_auc_score(testing_labels, predictions_test_updated))\n",
    "        predictions_test_sw = np.concatenate([predictions_test_sw, predictions_test_updated])\n",
    "\n",
    "        training_features = np.vstack(feature_list[i + 1 - num_chunks//2: i+1])\n",
    "        lengths_training_sw.append(len(training_features))\n",
    "        training_labels = np.hstack(label_list[i + 1 - num_chunks//2: i+1])\n",
    "\n",
    "    end_total_sw = time.time() - begin_total_sw\n",
    "    \n",
    "    \n",
    "    df_results_periodic_sw = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts', 'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Label_Costs'])\n",
    "    df_results_periodic_sw.loc[0] = [random_seed, 'periodic-sw', str(int(num_chunks//2)) + '/' + str(int(num_chunks//2)), partial_roc_auc_sw, np.mean(partial_roc_auc_sw), roc_auc_score(true_testing_labels, predictions_test_sw), predictions_test_sw, true_testing_labels,  total_train_sw, total_hyperparam_sw, total_test_sw, np.ones(25, dtype=int), len(true_testing_labels)]\n",
    "\n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_periodic_sw])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/rq3_periodic_sw_model_backblaze_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43300ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6d89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ea17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1b492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4e6f6a9",
   "metadata": {},
   "source": [
    "# Build Drift Detection based Model Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822c81b",
   "metadata": {},
   "source": [
    "### KS on all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475f69c",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc733ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_training_batches_list = list(range(0, num_chunks//2))\n",
    "\n",
    "\n",
    "for random_seed in random_seeds:\n",
    "\n",
    "    print('Random Seed:', random_seed)\n",
    "    necessary_label_annotation_effort = 0\n",
    "    total_time_training = 0\n",
    "    no_necessary_retrainings = 0\n",
    "    lengths_training_ks_all = []\n",
    "    partial_roc_auc_ks_all_model = []\n",
    "    \n",
    "    \n",
    "    predictions_test_ks_all_model = []\n",
    "    \n",
    "    \n",
    "\n",
    "    total_train_sw_all = 0\n",
    "    total_hyperparam_sw_ks_all = 0\n",
    "    total_test_time_ks_all = 0\n",
    "    \n",
    "    total_drift_detection_time = 0\n",
    "    total_distribution_extraction_time = 0\n",
    "    total_stat_test_time = 0\n",
    "    \n",
    "    \n",
    "    detected_drifts = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "    #print('Period', i-num_chunks//2)\n",
    "    \n",
    "        # obtain training features and labels\n",
    "        training_features_init = np.vstack(feature_list[0: i])\n",
    "        training_labels_init = np.hstack(label_list[0//2: i])\n",
    "        drift_alert = 0\n",
    "\n",
    "        # check if it is the first batch\n",
    "        if(i==num_chunks//2):\n",
    "            training_features = training_features_init\n",
    "            training_labels = training_labels_init\n",
    "            current_training_batches_list = initial_training_batches_list.copy()\n",
    "            print('Initial Training Batches', current_training_batches_list)\n",
    "\n",
    "        #print('Training for Model before Scaling', training_features)\n",
    "        \n",
    "\n",
    "        # scaler and downsampling on training data\n",
    "        update_scaler = StandardScaler()\n",
    "        training_features_model = update_scaler.fit_transform(training_features)\n",
    "        training_features_model, training_labels_model = downsampling(training_features_model, training_labels)\n",
    "\n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        \n",
    "        #print('Testing Model before Scaling', testing_features)\n",
    "        # scaling testing features\n",
    "        testing_features_model = update_scaler.transform(testing_features)\n",
    "        testing_labels_model = testing_labels\n",
    "\n",
    "\n",
    "         # training model\n",
    "        begin_train_sw_ks_all = time.time()\n",
    "\n",
    "\n",
    "        if(i==num_chunks//2 or need_to_retrain == 1):\n",
    "            print('RETRAINING MODEL')\n",
    "            \n",
    "            begin_train_sw_ks_all = time.time()\n",
    "        \n",
    "            begin_hyperparam_tunning_update = time.time()\n",
    "            model = RandomForestClassifier(random_state = random_seed)\n",
    "            random_search = RandomizedSearchCV(model,\n",
    "                                                       param_distributions = param_dist_rf,\n",
    "                                                       n_iter=N_ITER_SEARCH,\n",
    "                                                       scoring='roc_auc',\n",
    "                                                       cv=4, n_jobs=1, random_state = random_seed)\n",
    "\n",
    "            \n",
    "            random_search.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            update_model_ks_all = random_search.best_estimator_\n",
    "            \n",
    "            \n",
    "\n",
    "            end_hyperparam_tunning_update = time.time() - begin_hyperparam_tunning_update\n",
    "            \n",
    "            total_hyperparam_sw_ks_all = total_hyperparam_sw_ks_all + end_hyperparam_tunning_update\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            update_model_ks_all.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            end_train_sw_ks_all = time.time() - begin_train_sw_ks_all\n",
    "        \n",
    "            total_train_sw_all = total_train_sw_all + end_train_sw_ks_all\n",
    "        \n",
    "        \n",
    "        # evaluate model on testing data\n",
    "        \n",
    "        begin_test_time_ks_all = time.time()\n",
    "        predictions_test_updated = update_model_ks_all.predict(testing_features_model)\n",
    "        \n",
    "        end_test_time_ks_all = time.time() - begin_test_time_ks_all\n",
    "        total_test_time_ks_all = total_test_time_ks_all + end_test_time_ks_all\n",
    "\n",
    "        partial_roc_auc_ks_all_model.append(roc_auc_score(testing_labels_model, predictions_test_updated))\n",
    "        \n",
    "        predictions_test_ks_all_model = np.concatenate([predictions_test_ks_all_model, predictions_test_updated])\n",
    "        \n",
    "        \n",
    "        print('Predictions Test Batch', len(predictions_test_updated))\n",
    "        print('Prediction Test All', len(predictions_test_ks_all_model))\n",
    "        \n",
    "        \n",
    "        # Drift Detection\n",
    "        \n",
    "        need_to_retrain = 0\n",
    "        \n",
    "        print('MODEL', update_model_ks_all)\n",
    "        \n",
    "        \n",
    "        drift_time_start = time.time()\n",
    "        drift_alert, distribution_extraction_time, ks_test_time = ks_drift_detection(training_features_model, testing_features_model)\n",
    "        drift_time_end = time.time() - drift_time_start\n",
    "        \n",
    "        \n",
    "        total_distribution_extraction_time = total_distribution_extraction_time + distribution_extraction_time\n",
    "        total_stat_test_time = total_stat_test_time + ks_test_time\n",
    "        total_drift_detection_time = total_drift_detection_time + drift_time_end\n",
    "        \n",
    "        \n",
    "        detected_drifts.append(drift_alert)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        drift_time_start = time.time()\n",
    "        drift_alert, distribution_extraction_time, ks_test_time = ks_drift_detection(training_features_model, testing_features_model)\n",
    "        drift_time_end = time.time() - drift_time_start\n",
    "        \n",
    "        \n",
    "        total_distribution_extraction_time = total_distribution_extraction_time + distribution_extraction_time\n",
    "        total_stat_test_time = total_stat_test_time + ks_test_time\n",
    "        total_drift_detection_time = total_drift_detection_time + drift_time_end\n",
    "        \n",
    "                \n",
    "        if(drift_alert==1):\n",
    "        \n",
    "            need_to_retrain = 1\n",
    "            drift_alert = 0\n",
    "\n",
    "       \n",
    "       \n",
    "            \n",
    "            print('CHANGE OF TRAINING')\n",
    "\n",
    "            no_necessary_retrainings = no_necessary_retrainings + 1\n",
    "            necessary_label_annotation_effort = necessary_label_annotation_effort + len(testing_labels)\n",
    "\n",
    "            #new_training_features = np.concatenate([training_features[len(testing_features):], testing_features])\n",
    "            #new_training_labels = np.concatenate([training_labels[len(testing_labels):], testing_labels])\n",
    "            \n",
    "            \n",
    "            \n",
    "            current_training_batches_list.remove(current_training_batches_list[0])        \n",
    "            current_training_batches_list.append(i)\n",
    "        \n",
    "            #print('Current Training Batches',current_training_batches_list)\n",
    "            \n",
    "            \n",
    "            training_features_list_updated = [feature_list[i] for i in current_training_batches_list]\n",
    "            training_labels_list_updated = [label_list[i] for i in current_training_batches_list]\n",
    "        \n",
    "            training_features = np.vstack(training_features_list_updated)\n",
    "            training_labels = np.hstack(training_labels_list_updated)\n",
    "\n",
    "            #training_features = np.vstack(feature_list[i + 1 - num_chunks//2: i+1])\n",
    "            #training_labels = np.hstack(label_list[i + 1 - num_chunks//2: i+1])\n",
    "        \n",
    "        print('Current Training Batches',current_training_batches_list)\n",
    "    \n",
    "    \n",
    "    df_results_ks_all_model = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts_Overall',  'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Drift_Detection_Total_Time', 'Distribution_Extraction_Time', 'Statistical_Test_Time', 'Label_Costs'])\n",
    "    df_results_ks_all_model.loc[0] = [random_seed, 'KS_ALL', str(no_necessary_retrainings)+'/'+str(len(detected_drifts)), partial_roc_auc_ks_all_model, np.mean(partial_roc_auc_ks_all_model), roc_auc_score(true_testing_labels, predictions_test_ks_all_model), predictions_test_ks_all_model, true_testing_labels, total_train_sw_all, total_hyperparam_sw_ks_all, total_test_time_ks_all, detected_drifts, total_drift_detection_time, total_distribution_extraction_time, total_stat_test_time, necessary_label_annotation_effort]\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_ks_all_model])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/rq3_ks_all_sw_model_disk_data.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef34317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c0bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd685cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd09e5f4",
   "metadata": {},
   "source": [
    "### KS on PCA Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936334a2",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd42d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_training_batches_list = list(range(0, num_chunks//2))\n",
    "\n",
    "\n",
    "for random_seed in random_seeds:\n",
    "    \n",
    "    \n",
    "    print('Random Seed:', random_seed)\n",
    "    necessary_label_annotation_effort = 0\n",
    "    total_time_training = 0\n",
    "    no_necessary_retrainings = 0\n",
    "    lengths_training_ks_pca = []\n",
    "    partial_roc_auc_ks_pca_model = []\n",
    "    \n",
    "    \n",
    "    predictions_test_ks_pca_model = []\n",
    "    \n",
    "    \n",
    "\n",
    "    total_train_sw_pca = 0\n",
    "    total_hyperparam_sw_ks_pca = 0\n",
    "    total_test_time_ks_pca = 0\n",
    "    \n",
    "    total_drift_detection_time = 0\n",
    "    total_distribution_extraction_time = 0\n",
    "    total_stat_test_time = 0\n",
    "    total_pca_time = 0\n",
    "    \n",
    "    \n",
    "    detected_drifts = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "\n",
    "\n",
    "    \n",
    "        #print('Period', i-num_chunks//2)\n",
    "    \n",
    "        # obtain training features and labels\n",
    "        training_features_init = np.vstack(feature_list[0: i])\n",
    "        training_labels_init = np.hstack(label_list[0//2: i])\n",
    "        drift_alert = 0\n",
    "\n",
    "        # check if it is the first batch\n",
    "        if(i==num_chunks//2):\n",
    "            training_features = training_features_init\n",
    "            training_labels = training_labels_init\n",
    "            current_training_batches_list = initial_training_batches_list.copy()\n",
    "            print('Initial Training Batches', current_training_batches_list)\n",
    "\n",
    "        #print('Training for Model before Scaling', training_features)\n",
    "        \n",
    "\n",
    "        # scaler and downsampling for training data\n",
    "        update_scaler = StandardScaler()\n",
    "        training_features_model = update_scaler.fit_transform(training_features)\n",
    "        training_features_model, training_labels_model = downsampling(training_features_model, training_labels)\n",
    "\n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        \n",
    "        #print('Testing Model before Scaling', testing_features)\n",
    "        # scaling testing features\n",
    "        testing_features_model = update_scaler.transform(testing_features)\n",
    "        testing_labels_model = testing_labels\n",
    "\n",
    "\n",
    "         # training model\n",
    "        begin_train_sw_ks_pca = time.time()\n",
    "\n",
    "\n",
    "        if(i==num_chunks//2 or need_to_retrain == 1):\n",
    "            print('RETRAINING MODEL')\n",
    "            \n",
    "            begin_train_sw_ks_pca = time.time()\n",
    "        \n",
    "            begin_hyperparam_tunning_update = time.time()\n",
    "            model = RandomForestClassifier(random_state = random_seed)\n",
    "            random_search = RandomizedSearchCV(model,\n",
    "                                                       param_distributions = param_dist_rf,\n",
    "                                                       n_iter=N_ITER_SEARCH,\n",
    "                                                       scoring='roc_auc',\n",
    "                                                       cv=4, n_jobs=1, random_state = random_seed)\n",
    "\n",
    "            \n",
    "            random_search.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            update_model_ks_pca = random_search.best_estimator_\n",
    "            \n",
    "            \n",
    "\n",
    "            end_hyperparam_tunning_update = time.time() - begin_hyperparam_tunning_update\n",
    "            \n",
    "            total_hyperparam_sw_ks_pca = total_hyperparam_sw_ks_pca + end_hyperparam_tunning_update\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            update_model_ks_pca.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            end_train_sw_ks_pca = time.time() - begin_train_sw_ks_pca\n",
    "        \n",
    "            total_train_sw_pca = total_train_sw_pca + end_train_sw_ks_pca\n",
    "        \n",
    "        \n",
    "        # evaluate model on testing data\n",
    "        \n",
    "        begin_test_time_ks_pca = time.time()\n",
    "        predictions_test_updated = update_model_ks_pca.predict(testing_features_model)\n",
    "        \n",
    "        end_test_time_ks_pca = time.time() - begin_test_time_ks_pca\n",
    "        total_test_time_ks_pca = total_test_time_ks_pca + end_test_time_ks_pca\n",
    "\n",
    "        partial_roc_auc_ks_pca_model.append(roc_auc_score(testing_labels_model, predictions_test_updated))\n",
    "        \n",
    "        predictions_test_ks_pca_model = np.concatenate([predictions_test_ks_pca_model, predictions_test_updated])\n",
    "        \n",
    "        \n",
    "        print('Predictions Test Batch', len(predictions_test_updated))\n",
    "        print('Prediction Test All', len(predictions_test_ks_pca_model))\n",
    "        \n",
    "        \n",
    "        # Drift Detection\n",
    "        \n",
    "        need_to_retrain = 0\n",
    "        \n",
    "        print('MODEL', update_model_ks_pca)\n",
    "        \n",
    "        drift_time_start = time.time()\n",
    "        \n",
    "        # Extract PCA Features\n",
    "        \n",
    "        pca_computing_time_start = time.time()\n",
    "        \n",
    "        pca = PCA(n_components = 0.95, random_state = random_seed)\n",
    "        pca.fit(training_features_model)\n",
    "\n",
    "        df_train_features_sorted_pca = pca.transform(training_features_model)\n",
    "        df_test_features_sorted_pca = pca.transform(testing_features_model)\n",
    "        \n",
    "        pca_computing_time_end = time.time() - pca_computing_time_start\n",
    "        \n",
    "        \n",
    "        # Detect Drift\n",
    "        \n",
    "        drift_alert, distribution_extraction_time, ks_test_time = ks_drift_detection(df_train_features_sorted_pca, df_test_features_sorted_pca)\n",
    "        drift_time_end = time.time() - drift_time_start\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        total_distribution_extraction_time = total_distribution_extraction_time + distribution_extraction_time\n",
    "        total_stat_test_time = total_stat_test_time + ks_test_time\n",
    "        total_pca_time = total_pca_time + pca_computing_time_end\n",
    "        total_drift_detection_time = total_drift_detection_time + drift_time_end\n",
    "        \n",
    "        \n",
    "        detected_drifts.append(drift_alert)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(drift_alert==1):\n",
    "        \n",
    "            need_to_retrain = 1\n",
    "            drift_alert = 0\n",
    "\n",
    "       \n",
    "       \n",
    "            \n",
    "            print('CHANGE OF TRAINING')\n",
    "\n",
    "            no_necessary_retrainings = no_necessary_retrainings + 1\n",
    "            necessary_label_annotation_effort = necessary_label_annotation_effort + len(testing_labels)\n",
    "\n",
    "            #new_training_features = np.concatenate([training_features[len(testing_features):], testing_features])\n",
    "            #new_training_labels = np.concatenate([training_labels[len(testing_labels):], testing_labels])\n",
    "            \n",
    "            \n",
    "            \n",
    "            current_training_batches_list.remove(current_training_batches_list[0])        \n",
    "            current_training_batches_list.append(i)\n",
    "        \n",
    "            #print('Current Training Batches',current_training_batches_list)\n",
    "            \n",
    "            \n",
    "            training_features_list_updated = [feature_list[i] for i in current_training_batches_list]\n",
    "            training_labels_list_updated = [label_list[i] for i in current_training_batches_list]\n",
    "        \n",
    "            training_features = np.vstack(training_features_list_updated)\n",
    "            training_labels = np.hstack(training_labels_list_updated)\n",
    "\n",
    "            #training_features = np.vstack(feature_list[i + 1 - num_chunks//2: i+1])\n",
    "            #training_labels = np.hstack(label_list[i + 1 - num_chunks//2: i+1])\n",
    "        \n",
    "        print('Current Training Batches',current_training_batches_list)\n",
    "    \n",
    "    \n",
    "    df_results_ks_pca_model = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts_Overall',  'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Drift_Detection_Total_Time', 'PCA_Computing_time', 'Distribution_Extraction_Time', 'Statistical_Test_Time', 'Label_Costs'])\n",
    "    df_results_ks_pca_model.loc[0] = [random_seed, 'KS_PCA', str(no_necessary_retrainings)+'/'+str(len(detected_drifts)), partial_roc_auc_ks_pca_model, np.mean(partial_roc_auc_ks_pca_model), roc_auc_score(true_testing_labels, predictions_test_ks_pca_model), predictions_test_ks_pca_model, true_testing_labels, total_train_sw_pca, total_hyperparam_sw_ks_pca, total_test_time_ks_pca, detected_drifts, total_drift_detection_time, total_pca_time, total_distribution_extraction_time, total_stat_test_time, necessary_label_annotation_effort]\n",
    "    \n",
    "    \n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_ks_pca_model])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/rq3_ks_pca_sw_model_backblaze_data.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8348f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce7da27d",
   "metadata": {},
   "source": [
    "### Most Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937188f",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42455308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_training_batches_list = list(range(0, num_chunks//2))\n",
    "\n",
    "\n",
    "for random_seed in random_seeds:\n",
    "\n",
    "\n",
    "    print('Random Seed', random_seed)\n",
    "    no_necessary_retrainings = 0\n",
    "    necessary_label_annotation_effort = 0\n",
    "    total_time_training = 0\n",
    "    lengths_training_ks_fi = []\n",
    "    partial_roc_auc_ks_fi_model = []\n",
    "    \n",
    "    \n",
    "    predictions_test_ks_fi_model = []\n",
    "    \n",
    "\n",
    "\n",
    "    total_train_sw_fi = 0\n",
    "    total_hyperparam_sw_ks_fi = 0\n",
    "    total_test_time_ks_fi = 0\n",
    "    \n",
    "    total_ks_distribution_extraction = 0\n",
    "    total_ks_drift_detection = 0\n",
    "    total_feature_importance_extraction_time = 0\n",
    "    \n",
    "    detected_drifts = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "\n",
    "\n",
    "    \n",
    "        #print('Period', i-num_chunks//2)\n",
    "    \n",
    "        # obtain training features and labels\n",
    "        training_features_init = np.vstack(feature_list[0: i])\n",
    "        training_labels_init = np.hstack(label_list[0//2: i])\n",
    "        drift_alert = 0\n",
    "\n",
    "        # check if it is the first batch\n",
    "        if(i==num_chunks//2):\n",
    "            training_features = training_features_init\n",
    "            training_labels = training_labels_init\n",
    "            current_training_batches_list = initial_training_batches_list.copy()\n",
    "            print('Initial Training Batches', current_training_batches_list)\n",
    "\n",
    "        #print('Training for Model before Scaling', training_features)\n",
    "        \n",
    "\n",
    "        # scaler and downsampling for training data\n",
    "        update_scaler = StandardScaler()\n",
    "        training_features_model = update_scaler.fit_transform(training_features)\n",
    "        training_features_model, training_labels_model = downsampling(training_features_model, training_labels)\n",
    "\n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        \n",
    "        #print('Testing Model before Scaling', testing_features)\n",
    "        # scaling testing features\n",
    "        testing_features_model = update_scaler.transform(testing_features)\n",
    "        testing_labels_model = testing_labels\n",
    "\n",
    "\n",
    "         # training model\n",
    "        begin_train_sw_ks_fi = time.time()\n",
    "\n",
    "\n",
    "        if(i==num_chunks//2 or need_to_retrain == 1):\n",
    "            print('RETRAINING MODEL')\n",
    "            \n",
    "            begin_train_sw_ks_fi = time.time()\n",
    "        \n",
    "            begin_hyperparam_tunning_update = time.time()\n",
    "            model = RandomForestClassifier(random_state = random_seed)\n",
    "            random_search = RandomizedSearchCV(model,\n",
    "                                                       param_distributions = param_dist_rf,\n",
    "                                                       n_iter=N_ITER_SEARCH,\n",
    "                                                       scoring='roc_auc',\n",
    "                                                       cv=4, n_jobs=1, random_state = random_seed)\n",
    "\n",
    "            \n",
    "            random_search.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            update_model_ks_fi = random_search.best_estimator_\n",
    "            \n",
    "            \n",
    "\n",
    "            end_hyperparam_tunning_update = time.time() - begin_hyperparam_tunning_update\n",
    "            \n",
    "            total_hyperparam_sw_ks_fi = total_hyperparam_sw_ks_fi + end_hyperparam_tunning_update\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            update_model_ks_fi.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            end_train_sw_ks_fi = time.time() - begin_train_sw_ks_fi\n",
    "        \n",
    "            total_train_sw_fi = total_train_sw_fi + end_train_sw_ks_fi\n",
    "        \n",
    "        \n",
    "        # evaluate model on testing data\n",
    "        \n",
    "        begin_test_time_ks_fi = time.time()\n",
    "        predictions_test_updated = update_model_ks_fi.predict(testing_features_model)\n",
    "        \n",
    "        end_test_time_ks_fi = time.time() - begin_test_time_ks_fi\n",
    "        total_test_time_ks_fi = total_test_time_ks_fi + end_test_time_ks_fi\n",
    "\n",
    "        partial_roc_auc_ks_fi_model.append(roc_auc_score(testing_labels_model, predictions_test_updated))\n",
    "        \n",
    "        predictions_test_ks_fi_model = np.concatenate([predictions_test_ks_fi_model, predictions_test_updated])\n",
    "        \n",
    "        \n",
    "        print('Predictions Test Batch', len(predictions_test_updated))\n",
    "        print('Prediction Test All', len(predictions_test_ks_fi_model))\n",
    "        \n",
    "        \n",
    "        # Drift Detection\n",
    "        \n",
    "        need_to_retrain = 0\n",
    "        \n",
    "        print('MODEL', update_model_ks_fi)\n",
    "        \n",
    "        drift_time_start = time.time()\n",
    "        \n",
    "        # Extract Most Important Features\n",
    "        feature_importance_extraction_start = time.time()\n",
    "        \n",
    "        important_features = important_features_extraction(update_model_ks_fi, features_disk_failure)\n",
    "        print('Important Features', important_features)\n",
    "        print(len(important_features))\n",
    "\n",
    "        # filter non-important features from train and test\n",
    "\n",
    "        training_important_features_model = filtering_non_important_features(training_features_model, features_disk_failure, important_features)\n",
    "        testing_important_features_model = filtering_non_important_features(testing_features_model, features_disk_failure, important_features)\n",
    "\n",
    "        feature_importance_extraction_end = time.time() - feature_importance_extraction_start\n",
    "        \n",
    "        \n",
    "        # Detect Drift\n",
    "        \n",
    "        drift_alert, distribution_extraction_time, ks_test_time = ks_drift_detection(training_important_features_model, testing_important_features_model)\n",
    "        drift_time_end = time.time() - drift_time_start\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        total_distribution_extraction_time = total_distribution_extraction_time + distribution_extraction_time\n",
    "        total_stat_test_time = total_stat_test_time + ks_test_time\n",
    "        total_feature_importance_extraction_time = total_feature_importance_extraction_time + feature_importance_extraction_end\n",
    "        total_drift_detection_time = total_drift_detection_time + drift_time_end\n",
    "        \n",
    "        \n",
    "        detected_drifts.append(drift_alert)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(drift_alert==1):\n",
    "        \n",
    "            need_to_retrain = 1\n",
    "            drift_alert = 0\n",
    "\n",
    "       \n",
    "       \n",
    "            \n",
    "            print('CHANGE OF TRAINING')\n",
    "\n",
    "            no_necessary_retrainings = no_necessary_retrainings + 1\n",
    "            necessary_label_annotation_effort = necessary_label_annotation_effort + len(testing_labels)\n",
    "\n",
    "            #new_training_features = np.concatenate([training_features[len(testing_features):], testing_features])\n",
    "            #new_training_labels = np.concatenate([training_labels[len(testing_labels):], testing_labels])\n",
    "            \n",
    "            \n",
    "            \n",
    "            current_training_batches_list.remove(current_training_batches_list[0])        \n",
    "            current_training_batches_list.append(i)\n",
    "        \n",
    "            #print('Current Training Batches',current_training_batches_list)\n",
    "            \n",
    "            \n",
    "            training_features_list_updated = [feature_list[i] for i in current_training_batches_list]\n",
    "            training_labels_list_updated = [label_list[i] for i in current_training_batches_list]\n",
    "        \n",
    "            training_features = np.vstack(training_features_list_updated)\n",
    "            training_labels = np.hstack(training_labels_list_updated)\n",
    "\n",
    "            #training_features = np.vstack(feature_list[i + 1 - num_chunks//2: i+1])\n",
    "            #training_labels = np.hstack(label_list[i + 1 - num_chunks//2: i+1])\n",
    "        \n",
    "        print('Current Training Batches',current_training_batches_list)\n",
    "    \n",
    "    \n",
    "    df_results_ks_fi_model = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts_Overall',  'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Drift_Detection_Total_Time', 'FI_Extraction_Time', 'Distribution_Extraction_Time', 'Statistical_Test_Time', 'Label_Costs'])\n",
    "    df_results_ks_fi_model.loc[0] = [random_seed, 'KS_FI', str(no_necessary_retrainings)+'/'+str(len(detected_drifts)), partial_roc_auc_ks_fi_model, np.mean(partial_roc_auc_ks_fi_model), roc_auc_score(true_testing_labels, predictions_test_ks_fi_model), predictions_test_ks_fi_model, true_testing_labels, total_train_sw_fi, total_hyperparam_sw_ks_fi, total_test_time_ks_fi, detected_drifts, total_drift_detection_time, total_feature_importance_extraction_time, total_distribution_extraction_time, total_stat_test_time, necessary_label_annotation_effort]\n",
    "    \n",
    "    \n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_ks_fi_model])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/rq3_ks_FI_sw_model_backblaze_data.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0773373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
