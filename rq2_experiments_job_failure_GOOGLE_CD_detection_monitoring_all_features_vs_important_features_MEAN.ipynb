{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64c8c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d6bd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2751f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_intervals(dataset):\n",
    "    '''\n",
    "    Generate interval terminals, so that samples in each interval have:\n",
    "        interval_i = (timestamp >= terminal_i) and (timestamp < terminal_{i+1})\n",
    "\n",
    "    Args:\n",
    "        dataset (chr): Assuming only Backblaze (b) and Google (g) datasets exists\n",
    "    '''\n",
    "    if dataset == 'g':\n",
    "        # time unit in Google: millisecond, tracing time: 29 days\n",
    "        start_time = 604046279\n",
    "        unit_period = 24 * 60 * 60 * 1000 * 1000  # unit period: one day\n",
    "        end_time = start_time + 28*unit_period\n",
    "    elif dataset == 'b':\n",
    "        # time unit in Backblaze: month, tracing time: one year (12 months)\n",
    "        start_time = 1\n",
    "        unit_period = 1  # unit period: one month\n",
    "        end_time = start_time + 12*unit_period\n",
    "\n",
    "    # add one unit for the open-end of range function\n",
    "    terminals = [i for i in range(start_time, end_time+unit_period, unit_period)]\n",
    "\n",
    "    return terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc4808e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_natural_chunks(features, labels, terminals):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(terminals) - 1):\n",
    "        idx = np.logical_and(features[:, 0] >= terminals[i], features[:, 0] < terminals[i + 1])\n",
    "        feature_list.append(features[idx][:, 1:])\n",
    "        label_list.append(labels[idx])\n",
    "    return feature_list, label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e4987ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_features_by_importance(df_feature_importance, features_name):\n",
    "    # Extract Ranks\n",
    "    feature_imp_array_string = np.array(((df_feature_importance.FI[period].replace('[','')).replace(']','')).replace('\\n', '').split(' '))\n",
    "    #print('feature_imp_array_string', feature_imp_array_string)\n",
    "\n",
    "    # convert to float\n",
    "    feature_imp_array = [float(i) for i in feature_imp_array_string if i != '' ]\n",
    "\n",
    "    # consider only the most important features (importance > mean(feature_importances))\n",
    "    # extract mean?? of feature importance\n",
    "    mean_importance = np.mean(feature_imp_array)\n",
    "\n",
    "    zipped_features = list(zip(feature_imp_array, features_name))\n",
    "\n",
    "\n",
    "    sorted_features_zip = sorted(zipped_features, key = lambda x: x[0], reverse = True)\n",
    "\n",
    "   \n",
    "    return sorted_features_zip, mean_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcecbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "741c26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KS_on_features(df_train, df_test):\n",
    "    stat_test = stats.kstest\n",
    "    distribution_training = sns.distplot(np.array(df_train)).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    distribution_test = sns.distplot(np.array(df_test)).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    v, p = stat_test(distribution_training, distribution_test)\n",
    "    if(p<0.05):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6df31d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_preprocessing(DATASET_PATH, dataset):\n",
    "    \n",
    "    if(dataset=='b'):\n",
    "        \n",
    "        print('Data Reading and Preprocessing')\n",
    "        \n",
    "        # set data paths and columns names\n",
    "        features_disk_failure = ['smart_1_raw', 'smart_4_raw', 'smart_5_raw', 'smart_7_raw', 'smart_9_raw', 'smart_12_raw', 'smart_187_raw', 'smart_193_raw', 'smart_194_raw', 'smart_197_raw', 'smart_199_raw', \n",
    "                         'smart_4_raw_diff', 'smart_5_raw_diff', 'smart_9_raw_diff', 'smart_12_raw_diff', 'smart_187_raw_diff', 'smart_193_raw_diff', 'smart_197_raw_diff', 'smart_199_raw_diff']\n",
    "        columns = ['serial_number', 'date'] + features_disk_failure + ['label']\n",
    "        \n",
    "        # read dataset\n",
    "        df = pd.read_csv(DATASET_PATH, header=None)\n",
    "        df.columns = columns\n",
    "        # ignore serial number\n",
    "        df = df[df.columns[1:]]\n",
    "        \n",
    "        # transform date to date time\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "        \n",
    "        # divide on weeks\n",
    "        df['date'] = pd.Series(pd.DatetimeIndex(df['date']).day_of_year)\n",
    "        \n",
    "        print('Features and Labels Computing')\n",
    "        \n",
    "        # features and labels extraction and computation\n",
    "        features = df[df.columns[:-1]].to_numpy()\n",
    "        labels = df[df.columns[-1]].to_numpy()\n",
    "        feature_list, label_list = obtain_natural_chunks(features, labels, obtain_intervals('b'))\n",
    "        \n",
    "    elif(dataset=='g'):\n",
    "        \n",
    "        print('Data Reading and Preprocessing')\n",
    "        \n",
    "        # set data paths and columns names\n",
    "        features_job_failure = ['User ID', 'Job Name', 'Scheduling Class',\n",
    "                   'Num Tasks', 'Priority', 'Diff Machine', 'CPU Requested', 'Mem Requested', 'Disk Requested',\n",
    "                   'Avg CPU', 'Avg Mem', 'Avg Disk', 'Std CPU', 'Std Mem', 'Std Disk']\n",
    "        columns_initial = ['Job ID', 'Status', 'Start Time', 'End Time'] + features_job_failure\n",
    "        \n",
    "        # read dataset\n",
    "        df = pd.read_csv(DATASET_PATH)\n",
    "        #df.columns = columns_initial\n",
    "        df = df.tail(-1)\n",
    "        # ignore Job ID\n",
    "        df = df.drop(['Job ID'], axis = 1)\n",
    "        columns = features_job_failure\n",
    "\n",
    "        include_end_time = False\n",
    "        \n",
    "        print('Features and Labels Preprocessing')\n",
    "        \n",
    "        # features and labels preprocessing\n",
    "        features = df[(['Start Time']+ features_job_failure)].to_numpy()\n",
    "        labels = (df['Status']==3).to_numpy()\n",
    "\n",
    "        # FEATURES PREPROCESSING\n",
    "        offset = (1 if include_end_time else 0)\n",
    "\n",
    "        # ENCODE USER ID\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        features[:, 1+offset] = le.fit_transform(features[:, 1+offset])\n",
    "\n",
    "        # ENCODE JOB NAME\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        features[:, 2+offset] = le.fit_transform(features[:, 2+offset])\n",
    "\n",
    "        features = features.astype(float)\n",
    "        \n",
    "        print('Features and Labels Computing')\n",
    "        \n",
    "        # features and labels extraction and computation\n",
    "        feature_list, label_list = obtain_natural_chunks(features, labels, obtain_intervals('g'))\n",
    "        \n",
    "    else:\n",
    "        print('Incorrect Dataset')\n",
    "    \n",
    "    return feature_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ed3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ab2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60cd22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../../../Documents/phd_related/data_sets_concept_drift/AIOps_failure_prediction/google_job_failure.csv'\n",
    "interval = 'd'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d0669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78946d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Reading and Preprocessing\n",
      "Features and Labels Preprocessing\n",
      "Features and Labels Computing\n"
     ]
    }
   ],
   "source": [
    "feature_list, label_list = features_labels_preprocessing(DATASET_PATH, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b2c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a8859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2273ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44021b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8da07134",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_drift_localization = '../../../Documents/phd_related/alibaba/results/results_r/rf_concept_drift_localization_job_google_r_avg.csv'\n",
    "random_seeds = ['1234', '4887', '597', '1959', '413', '44', '2969', '4971', '4913', '9591']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c1944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fe596d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Sig</th>\n",
       "      <th>Y</th>\n",
       "      <th>P</th>\n",
       "      <th>FI</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>D1_2</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2.251150</td>\n",
       "      <td>D2_3</td>\n",
       "      <td>[1.40656093e-01 6.77843712e-02 2.38335246e-02 ...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.183823</td>\n",
       "      <td>D3_4</td>\n",
       "      <td>[0.09965596 0.06313577 0.01863725 0.07117918 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>D4_5</td>\n",
       "      <td>[0.07262888 0.08244205 0.03470399 0.02823718 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.231693</td>\n",
       "      <td>D5_6</td>\n",
       "      <td>[0.1373757  0.06440213 0.02295284 0.04328491 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>267</td>\n",
       "      <td>False</td>\n",
       "      <td>0.132754</td>\n",
       "      <td>D25_26</td>\n",
       "      <td>[0.11301451 0.07830951 0.03246196 0.04946277 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>268</td>\n",
       "      <td>False</td>\n",
       "      <td>0.185512</td>\n",
       "      <td>D26_27</td>\n",
       "      <td>[0.10309081 0.0719297  0.02810484 0.03886336 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>269</td>\n",
       "      <td>False</td>\n",
       "      <td>0.040528</td>\n",
       "      <td>D27_28</td>\n",
       "      <td>[0.09824896 0.06445325 0.02718747 0.03470019 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>270</td>\n",
       "      <td>True</td>\n",
       "      <td>0.277025</td>\n",
       "      <td>D28_29</td>\n",
       "      <td>[0.09174494 0.05765307 0.03657926 0.04957106 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>271</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100150</td>\n",
       "      <td>D29_30</td>\n",
       "      <td>[7.33986888e-02 5.15970860e-02 2.26750586e-02 ...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X    Sig         Y       P  \\\n",
       "0      2   True       inf    D1_2   \n",
       "1      3   True  2.251150    D2_3   \n",
       "2      4  False  0.183823    D3_4   \n",
       "3      5  False  0.038504    D4_5   \n",
       "4      6   True  0.231693    D5_6   \n",
       "..   ...    ...       ...     ...   \n",
       "265  267  False  0.132754  D25_26   \n",
       "266  268  False  0.185512  D26_27   \n",
       "267  269  False  0.040528  D27_28   \n",
       "268  270   True  0.277025  D28_29   \n",
       "269  271  False  0.100150  D29_30   \n",
       "\n",
       "                                                    FI Dataset           Model  \n",
       "0       [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Google  Random Forests  \n",
       "1    [1.40656093e-01 6.77843712e-02 2.38335246e-02 ...  Google  Random Forests  \n",
       "2    [0.09965596 0.06313577 0.01863725 0.07117918 0...  Google  Random Forests  \n",
       "3    [0.07262888 0.08244205 0.03470399 0.02823718 0...  Google  Random Forests  \n",
       "4    [0.1373757  0.06440213 0.02295284 0.04328491 0...  Google  Random Forests  \n",
       "..                                                 ...     ...             ...  \n",
       "265  [0.11301451 0.07830951 0.03246196 0.04946277 0...  Google  Random Forests  \n",
       "266  [0.10309081 0.0719297  0.02810484 0.03886336 0...  Google  Random Forests  \n",
       "267  [0.09824896 0.06445325 0.02718747 0.03470019 0...  Google  Random Forests  \n",
       "268  [0.09174494 0.05765307 0.03657926 0.04957106 0...  Google  Random Forests  \n",
       "269  [7.33986888e-02 5.15970860e-02 2.26750586e-02 ...  Google  Random Forests  \n",
       "\n",
       "[270 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concept_drift = pd.read_csv(data_path_drift_localization)\n",
    "df_concept_drift = df_concept_drift.loc[:, ~df_concept_drift.columns.str.contains('^Unnamed')]\n",
    "df_concept_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda1596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d106197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Sig</th>\n",
       "      <th>Y</th>\n",
       "      <th>P</th>\n",
       "      <th>FI</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.132810</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.11471472 0.06489837 0.03771919 0.05409328 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "      <td>0.127868</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.10864288 0.06645777 0.03607146 0.05281076 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "      <td>0.090648</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.11109902 0.07531936 0.04025066 0.04276139 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>93</td>\n",
       "      <td>False</td>\n",
       "      <td>0.124602</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.11854283 0.06391657 0.03020959 0.05215946 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>0.111866</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.11561881 0.06474925 0.03841227 0.05422171 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>147</td>\n",
       "      <td>False</td>\n",
       "      <td>0.115662</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.11985708 0.07247942 0.03367332 0.04859606 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>0.224744</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.12498786 0.06309168 0.03772603 0.06141843 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>201</td>\n",
       "      <td>False</td>\n",
       "      <td>0.237429</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.13111437 0.06739682 0.03377451 0.05873947 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>228</td>\n",
       "      <td>False</td>\n",
       "      <td>0.173848</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.12922711 0.0631992  0.03272217 0.0654309  0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218024</td>\n",
       "      <td>D11_12</td>\n",
       "      <td>[0.13485554 0.0599576  0.03627941 0.05516142 0...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Random Forests</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X    Sig         Y       P  \\\n",
       "10    12  False  0.132810  D11_12   \n",
       "37    39  False  0.127868  D11_12   \n",
       "64    66  False  0.090648  D11_12   \n",
       "91    93  False  0.124602  D11_12   \n",
       "118  120  False  0.111866  D11_12   \n",
       "145  147  False  0.115662  D11_12   \n",
       "172  174  False  0.224744  D11_12   \n",
       "199  201  False  0.237429  D11_12   \n",
       "226  228  False  0.173848  D11_12   \n",
       "253  255  False  0.218024  D11_12   \n",
       "\n",
       "                                                    FI Dataset           Model  \n",
       "10   [0.11471472 0.06489837 0.03771919 0.05409328 0...  Google  Random Forests  \n",
       "37   [0.10864288 0.06645777 0.03607146 0.05281076 0...  Google  Random Forests  \n",
       "64   [0.11109902 0.07531936 0.04025066 0.04276139 0...  Google  Random Forests  \n",
       "91   [0.11854283 0.06391657 0.03020959 0.05215946 0...  Google  Random Forests  \n",
       "118  [0.11561881 0.06474925 0.03841227 0.05422171 0...  Google  Random Forests  \n",
       "145  [0.11985708 0.07247942 0.03367332 0.04859606 0...  Google  Random Forests  \n",
       "172  [0.12498786 0.06309168 0.03772603 0.06141843 0...  Google  Random Forests  \n",
       "199  [0.13111437 0.06739682 0.03377451 0.05873947 0...  Google  Random Forests  \n",
       "226  [0.12922711 0.0631992  0.03272217 0.0654309  0...  Google  Random Forests  \n",
       "253  [0.13485554 0.0599576  0.03627941 0.05516142 0...  Google  Random Forests  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concept_drift[df_concept_drift.P == 'D11_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9cc0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_job_failure = ['User ID', 'Job Name', 'Scheduling Class',\n",
    "                   'Num Tasks', 'Priority', 'Diff Machine', 'CPU Requested', 'Mem Requested', 'Disk Requested',\n",
    "                   'Avg CPU', 'Avg Mem', 'Avg Disk', 'Std CPU', 'Std Mem', 'Std Disk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce7d7af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [01:26<00:00,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results All Features [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Results Important Features [1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Results PCA Features [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "no_overall_correct_all_total = []\n",
    "no_overall_correct_important_total = []\n",
    "no_overall_correct_pca_total = []\n",
    "\n",
    "no_drift_correct_all_total = []\n",
    "no_drift_correct_important_total = []\n",
    "no_drift_correct_pca_total = []\n",
    "\n",
    "no_non_drift_correct_all_total = []\n",
    "no_non_drift_correct_important_total = []\n",
    "no_non_drift_correct_pca_total = []\n",
    "\n",
    "\n",
    "random_seed_all = []\n",
    "\n",
    "\n",
    "\n",
    "drifts_true_job = []\n",
    "for k in range(0, len(df_concept_drift.Sig.values)):\n",
    "    if(df_concept_drift.Sig.values[k]==True):\n",
    "        drifts_true_job.append(1)\n",
    "    else:\n",
    "        drifts_true_job.append(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "ks_results_all_features = []\n",
    "ks_results_important_features = []\n",
    "ks_results_pca_features = []\n",
    "\n",
    "\n",
    "for period in tqdm(range(0, len(feature_list)-1)):\n",
    "#for period in tqdm(range(1,2)):\n",
    "\n",
    "\n",
    "    #print('Before Scale Train', feature_list[period])\n",
    "    #print('Before Scale Test', feature_list[period+1])\n",
    "\n",
    "    # extract features train and test\n",
    "    training_features = scaler.fit_transform(feature_list[period])\n",
    "    testing_features = scaler.transform(feature_list[period+1])\n",
    "\n",
    "    # convert numpy array to Pandas Dataframe\n",
    "    df_train_features = pd.DataFrame(training_features, columns = features_job_failure)\n",
    "    df_test_features = pd.DataFrame(testing_features, columns = features_job_failure)\n",
    "\n",
    "    # Sort by Feature Importance to avoid         \n",
    "    sorted_features_zip, mean_importance = sorting_features_by_importance(df_concept_drift, features_job_failure)\n",
    "\n",
    "\n",
    "\n",
    "    # Using All Features\n",
    "    sorted_features_all = [i[1] for i in sorted_features_zip]\n",
    "    #print('length sorted_features All', len(sorted_features_all))\n",
    "    df_train_features_sorted_all = df_train_features[sorted_features_all]\n",
    "    df_test_features_sorted_all = df_test_features[sorted_features_all]\n",
    "\n",
    "    # Using Most Important Features\n",
    "\n",
    "    sorted_important_features_filter = [x for x in sorted_features_zip if x[0]>=mean_importance]\n",
    "    sorted_features_important = [i[1] for i in sorted_important_features_filter]\n",
    "    #print('length sorted_features Important', len(sorted_features_important))\n",
    "\n",
    "    df_train_features_sorted_important = df_train_features[sorted_features_important]\n",
    "    df_test_features_sorted_important = df_test_features[sorted_features_important]\n",
    "\n",
    "    # Using PCA on Features\n",
    "    # reduce features dimensionality using PCA\n",
    "    pca = PCA(n_components = 0.95)\n",
    "    pca.fit(df_train_features_sorted_all)\n",
    "\n",
    "    df_train_features_sorted_pca = pca.transform(df_train_features_sorted_all)\n",
    "    df_test_features_sorted_pca = pca.transform(df_test_features_sorted_all)\n",
    "\n",
    "\n",
    "    ks_results_all_features.append(KS_on_features(df_train_features_sorted_all, df_test_features_sorted_all))\n",
    "    ks_results_important_features.append(KS_on_features(df_train_features_sorted_important, df_test_features_sorted_important))\n",
    "    ks_results_pca_features.append(KS_on_features(df_train_features_sorted_pca, df_test_features_sorted_pca))\n",
    "\n",
    "\n",
    "print('Results All Features', ks_results_all_features)\n",
    "print('Results Important Features', ks_results_important_features)\n",
    "print('Results PCA Features', ks_results_pca_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87171bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d5cb749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(ks_results_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a19bf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(ks_results_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ba77280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(ks_results_pca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bd258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22285f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ks_results_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2c16a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ks_results_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa5d703b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ks_results_pca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2971481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ks_results_all_features * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3507efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_results_all_features_all_rs = ks_results_all_features * 10\n",
    "ks_results_important_features_all_rs = ks_results_important_features * 10\n",
    "ks_results_pca_features_all_rs = ks_results_pca_features * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65ff70a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [00:00<00:00, 561458.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "no_overall_correct_all = 0\n",
    "no_drift_correct_all = 0\n",
    "no_non_drift_correct_all = 0\n",
    "\n",
    "\n",
    "no_overall_correct_important = 0\n",
    "no_drift_correct_important = 0\n",
    "no_non_drift_correct_important = 0\n",
    "\n",
    "no_overall_correct_pca = 0\n",
    "no_drift_correct_pca = 0\n",
    "no_non_drift_correct_pca = 0\n",
    "\n",
    "for j in tqdm(range(0, len(ks_results_all_features_all_rs))):\n",
    "\n",
    "    # Overall correct all 3 cases\n",
    "    if(ks_results_all_features_all_rs[j]==drifts_true_job[j]):\n",
    "        no_overall_correct_all = no_overall_correct_all + 1\n",
    "\n",
    "    if(ks_results_important_features_all_rs[j]==drifts_true_job[j]):\n",
    "        no_overall_correct_important = no_overall_correct_important + 1\n",
    "\n",
    "    if(ks_results_pca_features_all_rs[j]==drifts_true_job[j]):\n",
    "        no_overall_correct_pca = no_overall_correct_pca + 1\n",
    "\n",
    "    # Correctly Identified Drifts all 3 cases\n",
    "\n",
    "    # All Features\n",
    "    if(drifts_true_job[j]==1):\n",
    "        if(ks_results_all_features_all_rs[j]==drifts_true_job[j]):\n",
    "            no_drift_correct_all = no_drift_correct_all + 1\n",
    "\n",
    "    # Most Important Features\n",
    "    if(drifts_true_job[j]==1):\n",
    "        if(ks_results_important_features_all_rs[j]==drifts_true_job[j]):\n",
    "            no_drift_correct_important = no_drift_correct_important + 1\n",
    "\n",
    "    # PCA on Features\n",
    "    if(drifts_true_job[j]==1):\n",
    "        if(ks_results_pca_features_all_rs[j]==drifts_true_job[j]):\n",
    "            no_drift_correct_pca = no_drift_correct_pca + 1\n",
    "\n",
    "     # Correctly Identified Non-Drift all 3 cases\n",
    "\n",
    "    # All Features\n",
    "    if(drifts_true_job[j]==0):\n",
    "        if(ks_results_all_features_all_rs[j]==drifts_true_job[j]):\n",
    "            no_non_drift_correct_all = no_non_drift_correct_all + 1\n",
    "\n",
    "    # Most Important Features\n",
    "    if(drifts_true_job[j]==0):\n",
    "        if(ks_results_important_features_all_rs[j]==drifts_true_job[j]):\n",
    "            no_non_drift_correct_important = no_non_drift_correct_important + 1\n",
    "\n",
    "    # PCA on Features\n",
    "    if(drifts_true_job[j]==0):\n",
    "        if(ks_results_pca_features_all_rs[j]==drifts_true_job[j]):\n",
    "            no_non_drift_correct_pca = no_non_drift_correct_pca + 1\n",
    "\n",
    "# Compute Metrics for all Random Seeds\n",
    "\n",
    "# Overall Correct Predictions\n",
    "overall_correct_prediction_score_all = no_overall_correct_all/len(drifts_true_job)\n",
    "overall_correct_prediction_score_important = no_drift_correct_important/len(drifts_true_job)\n",
    "overall_correct_prediction_score_pca = no_overall_correct_pca/len(drifts_true_job)\n",
    "\n",
    "no_overall_correct_all_total.append(overall_correct_prediction_score_all)\n",
    "no_overall_correct_important_total.append(overall_correct_prediction_score_important)\n",
    "no_overall_correct_pca_total.append(overall_correct_prediction_score_pca)\n",
    "\n",
    "# Correctly Identified Drifts\n",
    "\n",
    "drift_correct_prediction_score_all = no_drift_correct_all/len(np.nonzero(drifts_true_job)[0])\n",
    "drift_correct_prediction_score_important = no_drift_correct_important/len(np.nonzero(drifts_true_job)[0])\n",
    "drift_correct_prediction_score_pca = no_drift_correct_pca/len(np.nonzero(drifts_true_job)[0])\n",
    "\n",
    "no_drift_correct_all_total.append(drift_correct_prediction_score_all)\n",
    "no_drift_correct_important_total.append(drift_correct_prediction_score_important)\n",
    "no_drift_correct_pca_total.append(drift_correct_prediction_score_pca)\n",
    "\n",
    "\n",
    "# Correctly Identified Non-Drifts\n",
    "\n",
    "non_drift_correct_prediction_score_all = no_non_drift_correct_all/(len(drifts_true_job) - len(np.nonzero(drifts_true_job)[0]))\n",
    "non_drift_correct_prediction_score_important = no_non_drift_correct_important/(len(drifts_true_job) - len(np.nonzero(drifts_true_job)[0]))\n",
    "non_drift_correct_prediction_score_pca = no_non_drift_correct_pca/(len(drifts_true_job) - len(np.nonzero(drifts_true_job)[0]))\n",
    "\n",
    "\n",
    "no_non_drift_correct_all_total.append(non_drift_correct_prediction_score_all)\n",
    "no_non_drift_correct_important_total.append(non_drift_correct_prediction_score_important)\n",
    "no_non_drift_correct_pca_total.append(non_drift_correct_prediction_score_pca)\n",
    "\n",
    "#random_seed_all.append([random_seeds[i-1]]*len(feature_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0951781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09369583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f4374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d496fed7",
   "metadata": {},
   "source": [
    "### Results All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1a0c005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6296296296296297"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_overall_correct_all_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e0ae96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_drift_correct_all_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1829864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_non_drift_correct_all_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae222af6",
   "metadata": {},
   "source": [
    "### Results Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "200594ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5185185185185185"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_overall_correct_important_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35007aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_drift_correct_important_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cf18a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_non_drift_correct_important_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195e1d5",
   "metadata": {},
   "source": [
    "### Results PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85329bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5185185185185185"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_overall_correct_pca_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bd242c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470588235294118"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_drift_correct_pca_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f060ef2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(no_non_drift_correct_pca_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9caa25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1bd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c9518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
